{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching http://clubelo.com/\n",
      "Found 60 links in table\n",
      "Found 60 hrefs\n",
      "\n",
      "Total competition links found: 5\n",
      "http://clubelo.com//ENG\n",
      "http://clubelo.com//ESP\n",
      "http://clubelo.com//ITA\n",
      "http://clubelo.com//FRA\n",
      "http://clubelo.com//GER\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "from IPython.display import display\n",
    "import re\n",
    "\n",
    "# 1) Create a Session with a random or fixed User-Agent\n",
    "s = requests.Session()\n",
    "s.headers.update({\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/109.0.0.0 Safari/537.36\"\n",
    "    )\n",
    "})\n",
    "\n",
    "def get_soup(session, url):\n",
    "    \"\"\"Fetch a URL, return BeautifulSoup or None on failure.\"\"\"\n",
    "    try:\n",
    "        resp = session.get(url, timeout=10)\n",
    "        # Check status code\n",
    "        if resp.status_code == 200:\n",
    "            return BeautifulSoup(resp.text, 'html.parser')\n",
    "        elif resp.status_code == 429:\n",
    "            print(\"Received 429. Too many requests. Backing off.\")\n",
    "            # Wait longer or do an exponential backoff\n",
    "            time.sleep(60)\n",
    "            return None\n",
    "        else:\n",
    "            print(f\"Error: got status {resp.status_code} for {url}\")\n",
    "            return None\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return None\n",
    "    \n",
    "def get_competition_links(allowed_links, soup):\n",
    "    table = soup.find('table', class_='liste')\n",
    "    if not table:\n",
    "        print(\"Could not find table with class 'liste'\")\n",
    "        return []\n",
    "    \n",
    "    links = table.find_all('a')\n",
    "    print(f\"Found {len(links)} links in table\")\n",
    "\n",
    "    hrefs = [l.get('href') for l in links if l.get('href')]\n",
    "    print(f\"Found {len(hrefs)} hrefs\")\n",
    "    \n",
    "    #Select only for Top 5 competitions\n",
    "    competition_urls = []\n",
    "    for link in links:\n",
    "        if link['href'] in allowed_links:\n",
    "            competition_urls.append(f\"http://clubelo.com/{link['href']}\")\n",
    "         \n",
    "    return competition_urls\n",
    "\n",
    "def main():\n",
    "    elo_url = \"http://clubelo.com/\"\n",
    "    print(f\"Fetching {elo_url}\")\n",
    "    \n",
    "    soup_elo = get_soup(s, elo_url)\n",
    "    if not soup_elo:\n",
    "        print(\"Failed to get soup from main page\")\n",
    "        return\n",
    "    \n",
    "    allowed_links = {\"/ENG\", \"/ESP\", \"/ITA\", \"/GER\", \"/FRA\"}\n",
    "    competition_links = get_competition_links(allowed_links, soup_elo)\n",
    "    print(f\"\\nTotal competition links found: {len(competition_links)}\")\n",
    "\n",
    "    for link in competition_links:\n",
    "        print(link)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
